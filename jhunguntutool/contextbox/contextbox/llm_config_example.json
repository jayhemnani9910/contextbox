{
  "default_provider": "openai",
  "enable_logging": true,
  "log_level": "INFO",
  "log_format": "json",
  "enable_monitoring": true,
  "monitoring_interval": 60,
  "providers": {
    "openai": {
      "api_key": "your_openai_api_key_here",
      "base_url": "https://api.openai.com/v1",
      "default_model": "gpt-3.5-turbo",
      "timeout": 30,
      "max_retries": 3,
      "retry_delay": 1.0,
      "models": {
        "gpt-3.5-turbo": {
          "model_type": "chat",
          "max_tokens": 4096,
          "temperature": 0.7,
          "top_p": 1.0,
          "frequency_penalty": 0.0,
          "presence_penalty": 0.0,
          "cost_per_input_token": 0.0015,
          "cost_per_output_token": 0.002
        },
        "gpt-4": {
          "model_type": "chat",
          "max_tokens": 8192,
          "temperature": 0.7,
          "top_p": 1.0,
          "cost_per_input_token": 0.03,
          "cost_per_output_token": 0.06
        },
        "text-embedding-ada-002": {
          "model_type": "embeddings",
          "max_tokens": 8191,
          "cost_per_input_token": 0.0004
        }
      },
      "rate_limit": {
        "requests_per_minute": 60,
        "requests_per_hour": 1000,
        "tokens_per_minute": 100000,
        "burst_limit": 10
      },
      "cost_config": {
        "track_usage": true,
        "track_costs": true,
        "budget_limit": 100.0,
        "alert_threshold": 0.8
      }
    },
    "anthropic": {
      "api_key": "your_anthropic_api_key_here",
      "base_url": "https://api.anthropic.com",
      "default_model": "claude-3-sonnet-20240229",
      "timeout": 30,
      "max_retries": 3,
      "retry_delay": 1.0,
      "models": {
        "claude-3-haiku-20240307": {
          "model_type": "chat",
          "max_tokens": 4096,
          "temperature": 0.7,
          "top_p": 1.0,
          "cost_per_input_token": 0.00025,
          "cost_per_output_token": 0.00125
        },
        "claude-3-sonnet-20240229": {
          "model_type": "chat",
          "max_tokens": 8192,
          "temperature": 0.7,
          "top_p": 1.0,
          "cost_per_input_token": 0.003,
          "cost_per_output_token": 0.015
        }
      },
      "rate_limit": {
        "requests_per_minute": 50,
        "requests_per_hour": 1000,
        "tokens_per_minute": 80000,
        "burst_limit": 5
      },
      "cost_config": {
        "track_usage": true,
        "track_costs": true,
        "budget_limit": 50.0,
        "alert_threshold": 0.8
      }
    },
    "azure_openai": {
      "api_key": "your_azure_api_key_here",
      "base_url": "https://your-resource.openai.azure.com/",
      "default_model": "gpt-35-turbo",
      "timeout": 60,
      "max_retries": 3,
      "retry_delay": 1.0,
      "models": {
        "gpt-35-turbo": {
          "model_type": "chat",
          "max_tokens": 4096,
          "temperature": 0.7,
          "top_p": 1.0,
          "cost_per_input_token": 0.0005,
          "cost_per_output_token": 0.0015
        },
        "gpt-4": {
          "model_type": "chat",
          "max_tokens": 8192,
          "temperature": 0.7,
          "top_p": 1.0,
          "cost_per_input_token": 0.03,
          "cost_per_output_token": 0.06
        }
      },
      "rate_limit": {
        "requests_per_minute": 100,
        "requests_per_hour": 1000,
        "tokens_per_minute": 150000,
        "burst_limit": 20
      },
      "cost_config": {
        "track_usage": true,
        "track_costs": true,
        "budget_limit": 200.0,
        "alert_threshold": 0.8
      }
    },
    "local": {
      "api_key": null,
      "base_url": "http://localhost:8080/v1",
      "default_model": "local-model",
      "timeout": 120,
      "max_retries": 1,
      "retry_delay": 0.5,
      "models": {
        "local-model": {
          "model_type": "chat",
          "max_tokens": 4096,
          "temperature": 0.7,
          "top_p": 1.0,
          "cost_per_input_token": 0.0,
          "cost_per_output_token": 0.0
        }
      },
      "rate_limit": {
        "requests_per_minute": 1000,
        "requests_per_hour": 10000,
        "tokens_per_minute": 1000000,
        "burst_limit": 50
      },
      "cost_config": {
        "track_usage": true,
        "track_costs": false,
        "budget_limit": null,
        "alert_threshold": 0.8
      }
    }
  }
}